{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from gan import output\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_static = pd.read_pickle('../../../../../../Master Thesis/data/preprocessed/tumours_patients_2017_train.pickle').set_index('eid')\n",
    "df_treatments = pd.read_pickle('../../../../../../Master Thesis/data/preprocessed/treatments_2017_train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoppelGANgerTransformer:\n",
    "    \"\"\"\n",
    "    Class that transforms patients covariates and treatments data to format used for DoppelGANger\n",
    "    \"\"\"\n",
    "    def __init__(self, primary_key, treatment_col, order_col, max_nr_treatments, transformer_static, transformer_treatments):\n",
    "        self.primary_key = primary_key\n",
    "        self.treatment_col = treatment_col\n",
    "        self.order_col = order_col\n",
    "        self.max_nr_treatments = max_nr_treatments\n",
    "        self.transformer_static = transformer_static\n",
    "        self.transformer_treatments = transformer_treatments\n",
    "        \n",
    "    def transform(self, df_static, df_treatments): \n",
    "        df_static = df_static.copy()\n",
    "        df_treatments = df_treatments.copy()\n",
    "        \n",
    "        ##### TREATMENTS #####\n",
    "        \n",
    "        # Sort df_treatments on primary key and order number\n",
    "        df_treatments = df_treatments.sort_values([self.primary_key, self.order_col])\n",
    "        df_treatments = df_treatments.set_index(self.primary_key)\n",
    "        \n",
    "        ## Encoding\n",
    "        # Transform\n",
    "        df_treatments = pd.DataFrame(self.transformer_treatments.fit_transform(df_treatments).toarray(),\n",
    "                                     columns=list(self.transformer_treatments.transformers_[0][1].get_feature_names(\n",
    "                                         [self.treatment_col])),\n",
    "                                     index=df_treatments.index)\n",
    "                \n",
    "        # One encoded list per timestamp\n",
    "        df_treatments['timestamp'] = df_treatments.values.tolist()\n",
    "        \n",
    "        # Groupby primary key to get list of timestamps per primary key\n",
    "        df_treatments = pd.DataFrame(df_treatments.groupby(self.primary_key)['timestamp'].apply(list))\n",
    "                \n",
    "        ## Gen flag\n",
    "        # Get length of sequence per primary key\n",
    "        df_treatments['length'] = df_treatments['timestamp'].apply(len)\n",
    "        \n",
    "        def get_gen_flag(length):\n",
    "            return length * [1.0] + (self.max_nr_treatments-length) * [0.0]\n",
    "        \n",
    "        df_treatments['data_gen_flag'] = df_treatments['length'].apply(get_gen_flag)\n",
    "        \n",
    "        ## Set timestamp to always contain maximum number of timestamps (zero padding)\n",
    "        def fix_data_timestamp(row):\n",
    "            timestamp = deepcopy(row['timestamp'])\n",
    "            to_append = self.max_nr_treatments-row['length']\n",
    "            for i in range(to_append):\n",
    "                timestamp.append(len(self.transformer_treatments.transformers_[0][1].get_feature_names(\n",
    "                    [self.treatment_col])) * [0]) \n",
    "            return timestamp\n",
    "        \n",
    "        df_treatments['timestamp'] = df_treatments.apply(lambda row: fix_data_timestamp(row), axis=1)\n",
    "        \n",
    "        # Drop unneeded length column\n",
    "        df_treatments = df_treatments.drop('length', axis=1).copy()\n",
    "        \n",
    "        # Get needed np arrays\n",
    "        data_feature = np.array(df_treatments['timestamp'].values.tolist())\n",
    "        data_gen_flag = np.array(df_treatments['data_gen_flag'].values.tolist())\n",
    "                \n",
    "        ##### STATIC #####\n",
    "        \n",
    "        # Only tumours in treatments df\n",
    "        df_static = df_static.loc[df_treatments.index]\n",
    "        \n",
    "        ## One-hot encoding\n",
    "        df_static = pd.DataFrame(self.transformer_static.fit_transform(df_static).toarray(),\n",
    "                                 columns=list(self.transformer_static.transformers_[0][1].get_feature_names(\n",
    "                                     df_static.columns)),\n",
    "                                 index=df_static.index)\n",
    "        \n",
    "        assert all(df_static.index == df_treatments.index), 'Primary keys of static and treatments dataframe do not match'\n",
    "        \n",
    "        data_attribute = df_static.values\n",
    "        \n",
    "        return data_feature, data_gen_flag, data_attribute\n",
    "    \n",
    "    def inverse_transform(self, data_feature, data_gen_flag, data_attribute):\n",
    "        ##### STATIC #####\n",
    "        \n",
    "        ## Inverse transform column transformers (One-hot encoding)\n",
    "        df_static_inverse = pd.DataFrame(self.transformer_static.transformers_[0][1].inverse_transform(data_attribute),\n",
    "                              columns=self.transformer_static.transformers_[0][2])\n",
    "        \n",
    "        ##### TREATMENTS #####\n",
    "        \n",
    "        ## Sample lengths inverse transform\n",
    "        lengths = [list(sample).count(1) for sample in data_gen_flag]\n",
    "        features_length_transformed = [list(sample_length[0][:sample_length[1]]) for sample_length in list(zip(data_feature, lengths))]\n",
    "        \n",
    "        ## Explode\n",
    "        # One for per treatment, multiple rows per primary key\n",
    "        df_treatments_inverse = pd.DataFrame({'timestamps': features_length_transformed}).explode('timestamps')\n",
    "        df_treatments_inverse.index.name = self.primary_key\n",
    "        df_treatments_inverse = df_treatments_inverse.reset_index()\n",
    "    \n",
    "        ## Inverse transform column transformers (One-hot encoding)\n",
    "        cat_features = [sample for sample in df_treatments_inverse['timestamps']]\n",
    "        \n",
    "        df_treatments_inverse = pd.DataFrame(self.transformer_treatments.transformers_[0][1].inverse_transform(cat_features),\n",
    "                                             columns=self.transformer_treatments.transformers_[0][2],\n",
    "                                             index=df_treatments_inverse[self.primary_key])\n",
    "        df_treatments_inverse.index.name = self.primary_key\n",
    "        df_treatments_inverse = df_treatments_inverse.reset_index()\n",
    "        \n",
    "        df_treatments_inverse[self.order_col] = df_treatments_inverse.groupby('eid').cumcount()+1\n",
    "        \n",
    "        df_treatments_inverse = df_treatments_inverse[[self.primary_key, self.treatment_col, self.order_col]].copy()\n",
    "        \n",
    "        return df_static_inverse, df_treatments_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and save original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_treatments = ColumnTransformer(transformers=\n",
    "                                           [('categorical_encoding', OneHotEncoder(), ['gbs_gebeurtenis_code'])])\n",
    "\n",
    "transformer_static = ColumnTransformer(transformers=\n",
    "                                       [('categorical_encoding', OneHotEncoder(), df_static.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = DoppelGANgerTransformer(primary_key='eid',\n",
    "                             treatment_col='gbs_gebeurtenis_code', \n",
    "                             order_col='gbs_vnr',\n",
    "                             max_nr_treatments=5,\n",
    "                             transformer_static=transformer_static,\n",
    "                             transformer_treatments=transformer_treatments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature, data_gen_flag, data_attribute = tf.transform(df_static, df_treatments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((191913, 5, 47), (191913, 5), (191913, 38))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feature.shape, data_gen_flag.shape, data_attribute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata needed by DoppelGANger (see their GitHub repository for more information)\n",
    "data_feature_output = [\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_treatments['gbs_gebeurtenis_code'].nunique(), normalization=None, is_gen_flag=False)]\n",
    "\n",
    "data_attribute_output = [\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['tum_topo_code'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['pat_geslacht_code'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['tum_differentiatiegraad_code'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['tum_lymfklieren_positief_atl'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['age_at_diagnosis'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['tum_topo_sublokalisatie_code'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['stadium'].nunique(), normalization=None, is_gen_flag=False),\n",
    "    output.Output(type_=output.OutputType.DISCRETE, dim=df_static['survival_1'].nunique(), normalization=None, is_gen_flag=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../../../../Master Thesis/data/doppelGANger/final/data_feature_output.pkl', 'wb') as file:\n",
    "    pickle.dump(data_feature_output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../../../../Master Thesis/data/doppelGANger/final/data_attribute_output.pkl', 'wb') as file:\n",
    "    pickle.dump(data_attribute_output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../../../../../../Master Thesis/data/doppelGANger/final/data_train.npz',\n",
    "         data_feature=data_feature,\n",
    "         data_attribute=data_attribute,\n",
    "         data_gen_flag=data_gen_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "After training DoppelGANger (training.py) and generating data (generating.ipynb), we should reverse transform the generated data to the right format (same format as original data). This is done by inverse transforming the DoppelGANgerTransformer class on the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "generated_data = np.load('./generated_data/generated_data.npz')\n",
    "\n",
    "generated_feature = generated_data[\"data_feature\"]\n",
    "generated_attribute = generated_data[\"data_attribute\"]\n",
    "generated_gen_flag = generated_data[\"data_gen_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "df_static_synth, df_treatments_synth = tf.inverse_transform(generated_feature, generated_gen_flag, generated_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_static_synth.to_pickle('../../synthetic_data/DGNP_tumours.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treatments_synth.to_pickle('../../synthetic_data/DGNP_treatments.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
